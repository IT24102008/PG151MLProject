{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fea4350e",
   "metadata": {},
   "source": [
    "## Group member 5: feature selection\n",
    "\n",
    "### Subtask:\n",
    "Based on the processed data, apply feature selection techniques to identify the most relevant features for predicting stroke. This could involve statistical methods, feature importance from models, or dimensionality reduction techniques (though PCA is assigned to Member 6). Explain the rationale behind the chosen feature selection method. Display the selected features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36f507e",
   "metadata": {},
   "source": [
    "**Reasoning**:\n",
    "Define the feature matrix X and the target variable y from the df_cleaned DataFrame, excluding 'stroke' and 'id'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bfc553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature matrix X: (5110, 16)\n",
      "Shape of target variable y: (5110,)\n"
     ]
    }
   ],
   "source": [
    "X = df_cleaned.drop(['stroke', 'id'], axis=1)\n",
    "y = df_cleaned['stroke']\n",
    "\n",
    "print(\"Shape of feature matrix X:\", X.shape)\n",
    "print(\"Shape of target variable y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73033dc",
   "metadata": {},
   "source": [
    "**Reasoning**:\n",
    "Train a RandomForestClassifier model on the data and get the feature importances.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9bd3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances (sorted):\n",
      "age                               2.616317e-01\n",
      "bmi                               2.594563e-01\n",
      "avg_glucose_level                 2.173858e-01\n",
      "gender_Male                       3.566488e-02\n",
      "Residence_type_Urban              3.525226e-02\n",
      "hypertension                      2.775140e-02\n",
      "smoking_status_never smoked       2.690523e-02\n",
      "work_type_Private                 2.563415e-02\n",
      "heart_disease                     2.459820e-02\n",
      "smoking_status_formerly smoked    2.228079e-02\n",
      "work_type_Self-employed           2.162083e-02\n",
      "smoking_status_smokes             2.114090e-02\n",
      "ever_married_Yes                  1.933248e-02\n",
      "work_type_children                1.294418e-03\n",
      "work_type_Never_worked            5.047267e-05\n",
      "gender_Other                      1.685171e-07\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Choose a feature selection method: Feature importance from RandomForestClassifier\n",
    "# Rationale: Tree-based models like RandomForest inherently provide feature importances based on how much\n",
    "# they reduce impurity or variance when splitting nodes on that feature. Features with higher\n",
    "# importance scores are considered more relevant for the prediction task. This method is\n",
    "# computationally efficient and provides a clear ranking of features.\n",
    "\n",
    "# Instantiate and train a RandomForestClassifier model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Create a pandas Series to store feature names and their importances\n",
    "feature_importance_series = pd.Series(feature_importances, index=X.columns)\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "sorted_feature_importances = feature_importance_series.sort_values(ascending=False)\n",
    "\n",
    "print(\"Feature Importances (sorted):\")\n",
    "print(sorted_feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0aa1ba",
   "metadata": {},
   "source": [
    "**Reasoning**:\n",
    "Select the most important features based on the sorted feature importances and print the selected features. A common approach is to select features that contribute significantly to the model's performance, often by setting a threshold on the importance score or selecting a fixed number of top features. For this task, I will select features with importance scores above a small threshold to exclude features with negligible importance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74f2af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected Features based on importance threshold:\n",
      "['age', 'bmi', 'avg_glucose_level', 'gender_Male', 'Residence_type_Urban', 'hypertension', 'smoking_status_never smoked', 'work_type_Private', 'heart_disease', 'smoking_status_formerly smoked', 'work_type_Self-employed', 'smoking_status_smokes', 'ever_married_Yes']\n"
     ]
    }
   ],
   "source": [
    "# Select features based on a threshold (e.g., importance > 0.01)\n",
    "# You can adjust this threshold based on the desired number of features or domain knowledge.\n",
    "selected_features = sorted_feature_importances[sorted_feature_importances > 0.01].index.tolist()\n",
    "\n",
    "print(\"\\nSelected Features based on importance threshold:\")\n",
    "print(selected_features)\n",
    "\n",
    "# Alternatively, you could select the top N features:\n",
    "# N = 10  # Example: select the top 10 features\n",
    "# top_n_features = sorted_feature_importances.head(N).index.tolist()\n",
    "# print(f\"\\nTop {N} Selected Features:\")\n",
    "# print(top_n_features)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
